---
# Neural collapse config file. All must be specified
Model:
  model-name: mlp_huge       # Name of model in "our_models"
  embedding-layers: True     # Intermediate layers to use for NC loss with weightings. "^" used to indicate start of network.

Data:
  dataset-id: stl10      # Which dataset-getter to use. Note that shapes are provided by the dataset
  batch-size: 128        # Mini-batch size
  do-augmentation: False # Whether to do data augmentation

Optimizer:
  loss: mseloss
  weight-decay: 5.e-4    # Weight decay
  lr: 0.025              # Learning rate
  lr-decay: 0.2
  lr-decay-steps: 3      # Number of learning rate decay steps
  momentum: 0.9          # Optimizer momentum
  epochs: 300            # Number of epochs to train for

Logging:
  # When to store weights and calculate measurements
  save-dir: logs/stl10/mlp_huge
  # log-interval: 10        # At what interval to log checkpoints. Always includes first 10 epochs
  log-epochs: [0, 1, 2, 3, 4, 5, 7, 10, 14, 20, 30, 40, 50, 60, 80, 100, 125, 150, 175, 200, 225, 250, 275, 300]  # Overrides log-interval

Measurements:
  measures: Fast
...
